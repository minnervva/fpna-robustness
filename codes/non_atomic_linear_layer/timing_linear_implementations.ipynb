{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c228ad7-e071-4a7d-ad46-685aebf9d2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cculver/anaconda3/envs/generalml/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/cculver/anaconda3/envs/generalml/lib/python3.10/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from linear_atomic import *\n",
    "from utilities import *\n",
    "\n",
    "def timing_fwd(layer, x):\n",
    "    eval_times = []\n",
    "    for i in range(10000):\n",
    "        start = time.time()\n",
    "        y=layer(x)\n",
    "        stop = time.time()\n",
    "        eval_times.append(stop-start)\n",
    "    eval_times = np.array(eval_times)[100:]*1_000\n",
    "    print(f\"{np.mean(eval_times)} +/- {np.std(eval_times)} ms\")\n",
    "\n",
    "def timing_bwd(layer, x):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    eval_times = []\n",
    "    for i in range(10000):\n",
    "        start = time.time()\n",
    "        y=layer(x)\n",
    "        loss = criterion(y, torch.tensor([0,0,0,0,0]))\n",
    "        loss.backward()\n",
    "        stop = time.time()\n",
    "        eval_times.append(stop-start)\n",
    "    eval_times = np.array(eval_times)[100:]*1_000\n",
    "    print(f\"{np.mean(eval_times)} +/- {np.std(eval_times)} ms\")\n",
    "\n",
    "def verify(m1, m2, x):\n",
    "    for i in range(100):\n",
    "        with torch.no_grad():\n",
    "            # one order of magnitude smaller then default\n",
    "            assert torch.allclose(m1(x),m2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce15583d-12e9-462c-a19e-23271e00bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([torch.rand((50,)),torch.rand((50,)),torch.rand((50,)),torch.rand((50,)),torch.rand((50,))])\n",
    "torchlinear = torch.nn.Linear(50,5)\n",
    "assign_fixed_params(torchlinear)\n",
    "#tatomiclinear = AtomicLinearTorch(50,5)\n",
    "atomiclinear = AtomicLinear(50,5)\n",
    "assign_fixed_params(atomiclinear)\n",
    "#verify(torchlinear, tatomiclinear, x)\n",
    "verify(torchlinear, atomiclinear, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d773b68-7768-4b47-90b7-a47377af4192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01688740470192649 +/- 0.0062367398067770825 ms\n",
      "0.01637567173350941 +/- 0.005354101167111169 ms\n",
      "0.015930045734752308 +/- 0.007992502326906412 ms\n",
      "0.015571382310655382 +/- 0.02248797307509372 ms\n"
     ]
    }
   ],
   "source": [
    "torchlinear.train()\n",
    "timing_fwd(torchlinear, x)\n",
    "timing_fwd(torchlinear, x)\n",
    "timing_fwd(torchlinear, x)\n",
    "timing_fwd(torchlinear, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d15f06c-0718-40fa-9be5-d1874225108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06584102457219904 +/- 0.015801440864727973 ms\n",
      "0.05933489462341925 +/- 0.055152096572485855 ms\n",
      "0.05929672356807825 +/- 0.024729653906895428 ms\n",
      "0.06663223709722962 +/- 0.0240427850455804 ms\n"
     ]
    }
   ],
   "source": [
    "atomiclinear.train()\n",
    "timing_fwd(atomiclinear, x)\n",
    "timing_fwd(atomiclinear, x)\n",
    "timing_fwd(atomiclinear, x)\n",
    "timing_fwd(atomiclinear, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d5ce3c3-0559-4977-af88-ca7c8b4d1760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cculver/anaconda3/envs/generalml/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19415275015012182 +/- 0.03382680670509419 ms\n",
      "0.1822450425889757 +/- 0.025134561913912813 ms\n",
      "0.1793385756136191 +/- 0.01995179039002832 ms\n",
      "0.1976560823845141 +/- 0.039601250323909605 ms\n"
     ]
    }
   ],
   "source": [
    "torchlinear.train()\n",
    "timing_bwd(torchlinear, x)\n",
    "timing_bwd(torchlinear, x)\n",
    "timing_bwd(torchlinear, x)\n",
    "timing_bwd(torchlinear, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad3a183-d6ab-49f7-a0e9-e6c4168244b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3188059546730735 +/- 0.04396411505149049 ms\n",
      "0.32028607647828383 +/- 0.0433615537967176 ms\n",
      "0.32733820905589095 +/- 0.057573046510339905 ms\n",
      "0.33203799315173216 +/- 0.07182746638358595 ms\n"
     ]
    }
   ],
   "source": [
    "atomiclinear.train()\n",
    "timing_bwd(atomiclinear, x)\n",
    "timing_bwd(atomiclinear, x)\n",
    "timing_bwd(atomiclinear, x)\n",
    "timing_bwd(atomiclinear, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a80a2-bdb0-4533-9023-50a383da4ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f46434f-cba3-40f9-b0cd-437da75bda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = atomiclinear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db380f7-e56a-4b58-8a24-7e407016fd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.2387e-07, grad_fn=<SumBackward0>)\n",
      "tensor(8.1956e-08, grad_fn=<SumBackward0>)\n",
      "tensor(-1.6093e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.6689e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.9802e-07, grad_fn=<SumBackward0>)\n",
      "tensor(5.9605e-07, grad_fn=<SumBackward0>)\n",
      "tensor(3.4571e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.7881e-07, grad_fn=<SumBackward0>)\n",
      "tensor(1.6093e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.6093e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-2.3842e-07, grad_fn=<SumBackward0>)\n",
      "tensor(4.1723e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.6226e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-3.5763e-07, grad_fn=<SumBackward0>)\n",
      "tensor(3.4273e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-5.3644e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.5928e-06, grad_fn=<SumBackward0>)\n",
      "tensor(6.5565e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.1458e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.5795e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-2.6226e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.7285e-06, grad_fn=<SumBackward0>)\n",
      "tensor(5.9605e-07, grad_fn=<SumBackward0>)\n",
      "tensor(1.7285e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.1325e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-5.9605e-08, grad_fn=<SumBackward0>)\n",
      "tensor(2.2650e-06, grad_fn=<SumBackward0>)\n",
      "tensor(4.3213e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-1.0580e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.4438e-06, grad_fn=<SumBackward0>)\n",
      "tensor(8.0466e-07, grad_fn=<SumBackward0>)\n",
      "tensor(1.3709e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.8312e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.9073e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-5.9605e-08, grad_fn=<SumBackward0>)\n",
      "tensor(1.5497e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.2054e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.2815e-06, grad_fn=<SumBackward0>)\n",
      "tensor(5.3644e-07, grad_fn=<SumBackward0>)\n",
      "tensor(-1.3113e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-1.7285e-06, grad_fn=<SumBackward0>)\n",
      "tensor(5.9605e-07, grad_fn=<SumBackward0>)\n",
      "tensor(-1.7881e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.1458e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-1.7881e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.4438e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-3.0398e-06, grad_fn=<SumBackward0>)\n",
      "tensor(7.1526e-07, grad_fn=<SumBackward0>)\n",
      "tensor(4.1723e-07, grad_fn=<SumBackward0>)\n",
      "tensor(3.5763e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.8312e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.8477e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-1.1325e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.4736e-06, grad_fn=<SumBackward0>)\n",
      "tensor(3.2634e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-1.4901e-06, grad_fn=<SumBackward0>)\n",
      "tensor(3.4571e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-1.5497e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.0266e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-3.2783e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.8908e-06, grad_fn=<SumBackward0>)\n",
      "tensor(8.9407e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.4438e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.5630e-06, grad_fn=<SumBackward0>)\n",
      "tensor(3.3975e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-4.7684e-07, grad_fn=<SumBackward0>)\n",
      "tensor(1.7881e-07, grad_fn=<SumBackward0>)\n",
      "tensor(1.1921e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.8477e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.1325e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.3246e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-9.5367e-07, grad_fn=<SumBackward0>)\n",
      "tensor(-8.3447e-07, grad_fn=<SumBackward0>)\n",
      "tensor(-5.3644e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.0117e-07, grad_fn=<SumBackward0>)\n",
      "tensor(-1.2517e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.6689e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.1325e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.0133e-06, grad_fn=<SumBackward0>)\n",
      "tensor(4.1127e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.7881e-07, grad_fn=<SumBackward0>)\n",
      "tensor(-8.9407e-08, grad_fn=<SumBackward0>)\n",
      "tensor(2.7120e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.3113e-06, grad_fn=<SumBackward0>)\n",
      "tensor(6.5565e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.3842e-07, grad_fn=<SumBackward0>)\n",
      "tensor(2.9802e-08, grad_fn=<SumBackward0>)\n",
      "tensor(7.4506e-07, grad_fn=<SumBackward0>)\n",
      "tensor(-3.5763e-07, grad_fn=<SumBackward0>)\n",
      "tensor(1.7881e-07, grad_fn=<SumBackward0>)\n",
      "tensor(1.2517e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-4.1723e-06, grad_fn=<SumBackward0>)\n",
      "tensor(1.1027e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-1.1921e-07, grad_fn=<SumBackward0>)\n",
      "tensor(1.9073e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.0266e-06, grad_fn=<SumBackward0>)\n",
      "tensor(8.0466e-07, grad_fn=<SumBackward0>)\n",
      "tensor(-7.1526e-07, grad_fn=<SumBackward0>)\n",
      "tensor(3.2783e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.0564e-06, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(torch.sum(atomiclinear(x)-base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a418e-ce65-452b-b848-894d5353227b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5dc26-17c0-4be8-a0d0-5d9334759f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc68064-161a-4836-88de-4c2a44ab2331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc15a33-a787-4c0a-94b8-9b9a4f37def9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4975441-0ab0-4edd-926c-661d11f2d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([torch.rand((10,)),torch.rand((10,))])\n",
    "nam = Classifier(False, 10, 2, 40)\n",
    "am = Classifier(True, 10, 2, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "797e6edb-8ce6-46ff-9846-c8ba3e1a4f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0121, -3.1367],\n",
       "        [ 6.2277, 11.6180]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nam(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27453add-fffe-4b33-b432-6fd70c7c1325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0121, -3.1367],\n",
       "        [ 6.2277, 11.6180]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5e76eb-4169-4a91-99e9-8a59044a0f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.1526e-06, grad_fn=<SumBackward0>)\n",
      "tensor(8.1062e-06, grad_fn=<SumBackward0>)\n",
      "tensor(9.2983e-06, grad_fn=<SumBackward0>)\n",
      "tensor(6.4373e-06, grad_fn=<SumBackward0>)\n",
      "tensor(6.1989e-06, grad_fn=<SumBackward0>)\n",
      "tensor(7.1526e-07, grad_fn=<SumBackward0>)\n",
      "tensor(4.7684e-06, grad_fn=<SumBackward0>)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "tensor(3.8147e-06, grad_fn=<SumBackward0>)\n",
      "tensor(2.3842e-06, grad_fn=<SumBackward0>)\n",
      "tensor(6.4373e-06, grad_fn=<SumBackward0>)\n",
      "tensor(6.6757e-06, grad_fn=<SumBackward0>)\n",
      "tensor(-3.8147e-06, grad_fn=<SumBackward0>)\n",
      "tensor(7.6294e-06, grad_fn=<SumBackward0>)\n",
      "tensor(8.5831e-06, grad_fn=<SumBackward0>)\n",
      "tensor(5.4836e-06, grad_fn=<SumBackward0>)\n",
      "tensor(6.4373e-06, grad_fn=<SumBackward0>)\n",
      "tensor(8.8215e-06, grad_fn=<SumBackward0>)\n",
      "tensor(3.0994e-06, grad_fn=<SumBackward0>)\n",
      "tensor(9.0599e-06, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "base = am(x)\n",
    "for i in range(20):\n",
    "    print(torch.sum(am(x) - base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10922def-b490-45ac-99d1-64cf6b7eaf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55b4dbed",
   "metadata": {},
   "source": [
    "## Try\n",
    "\n",
    "[:, None, :]\n",
    "\n",
    "vs \n",
    "\n",
    ".unsqueeze(dim=1) \n",
    "\n",
    "timing difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a23916f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005891323089599609\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "x = torch.rand((100,100))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    y = x[:,None,:]\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30eeea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027556419372558594\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "x = torch.rand((100,100))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    y = x.unsqueeze(dim=1)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e31e7082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b22f728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.unsqueeze(dim=1) == x[:,None,:]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2999de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
