{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from linear_atomic import *\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Permuter(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Permuter, self).__init__()\n",
    "        self.permlayer = LearnablePermutation(4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        perm_matrix = self.permlayer()\n",
    "        y = torch.matmul(perm_matrix,x)\n",
    "        return y[0]*y[1] + y[2]*y[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutenet = Permuter()\n",
    "loss = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(permutenet.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0, 4.0, 1.0, 3.0] -5.0\n",
      "tensor(20.9698, grad_fn=<MeanBackward0>)\n",
      "tensor(9.5237, grad_fn=<MeanBackward0>)\n",
      "tensor(3.0511, grad_fn=<MeanBackward0>)\n",
      "tensor(3.1561, grad_fn=<MeanBackward0>)\n",
      "tensor(4.2613, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0939, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2548, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0790, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cculver/anaconda3/envs/generalml/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9304, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1702, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8933, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4866, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5997, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1366, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1002, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1.,-2.,3.,4.])\n",
    "min = np.prod(np.abs(x))\n",
    "bestperm = x\n",
    "for perm in sp.utilities.iterables.multiset_permutations(x):\n",
    "    val = perm[0]*perm[1]+perm[2]*perm[3]\n",
    "    if val < min:\n",
    "        min = val\n",
    "        bestperm = perm\n",
    "\n",
    "print(bestperm, min)\n",
    "\n",
    "x = torch.tensor(x).to(torch.float32)\n",
    "y = torch.tensor([min]).to(torch.float32)\n",
    "\n",
    "permutenet = Permuter()\n",
    "loss = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(permutenet.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(1000):\n",
    "    pred = permutenet(x)\n",
    "    l = loss(pred, y)\n",
    "    if i % 50 == 0:\n",
    "        print(l)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8072e-05, 7.4230e-12, 9.9998e-01, 4.1758e-09],\n",
      "        [4.4695e-11, 1.0000e+00, 5.9108e-12, 4.2788e-11],\n",
      "        [9.9935e-01, 6.5385e-04, 6.2373e-12, 2.2591e-11],\n",
      "        [9.9980e-01, 1.9804e-04, 8.5603e-11, 5.7663e-10]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "tensor([ 3.0000, -2.0000,  0.9996,  0.9998], grad_fn=<MvBackward0>)\n"
     ]
    }
   ],
   "source": [
    "permutenet.eval()\n",
    "permutenet.train()\n",
    "permutenet(x)\n",
    "print(permutenet.permlayer.forward())\n",
    "print()\n",
    "print(torch.matmul(permutenet.permlayer.forward(),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cculver/code/determinism/fpna-robustness/codes/non_atomic_linear_layer/linear_atomic.py:127: UserWarning: Warning: In eval mode, not all rows and columns have exactly one '1'\n",
      "  warnings.warn(\"Warning: In eval mode, not all rows and columns have exactly one '1'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(72.)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutenet.eval()\n",
    "permutenet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
